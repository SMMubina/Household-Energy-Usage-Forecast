# -*- coding: utf-8 -*-
"""Final_Project_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PFoppJm3JuQ2oBjDw3Tj6S65mN3vr4Di
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Load Dataset with Optimizations

import pandas as pd

file_path = "/content/drive/MyDrive/Household Energy Usage Forecast/household_power_consumption.txt"
df = pd.read_csv(file_path, sep=';', low_memory=False, na_values=['?'])

df

print(df.info())                          # Check data types and missing values

# Convert Date and Time into a single Datetime column
df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', dayfirst=True)
df.drop(columns=['Date', 'Time'], inplace=True)

df.head()

print(df.isnull().sum())                       # Count missing values per column

# Fill Missing Values with Median

df.fillna(df.median(), inplace=True)

print(df.isnull().sum())  # Count missing values per column

# Convert to appropriate types

df = df.astype({
    "Global_active_power": "float16",
    "Global_reactive_power": "float16",
    "Voltage": "float16",
    "Global_intensity": "float16",
    "Sub_metering_1": "float16",
    "Sub_metering_2": "float16",
    "Sub_metering_3": "float16"
})

print(df.duplicated().sum())  # Check for duplicate rows

import seaborn as sns
import matplotlib.pyplot as plt

# Plot histogram for a specific column
sns.histplot(df['Global_active_power'], bins=30, kde=True)
plt.title('Distribution of Energy Usage')
plt.show()

import numpy as np

# Compute the correlation matrix
corr_matrix = df.corr()

# Create a heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

# Sample dataset
df = df.sample(frac=0.2, random_state=42)                            # Use 20% of the data for faster execution

# Define Features and Target
X = df[[ 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']]
y = df['Global_active_power']

# Train-Test Split

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardization

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

import numpy as np

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from xgboost import XGBRegressor



# Define models
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(n_estimators=50, n_jobs=-1, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, random_state=42),
    "Neural Network": MLPRegressor(hidden_layer_sizes=(30,30), max_iter=300, early_stopping=True, random_state=42),
    "XGBoost": XGBRegressor(n_estimators=50, learning_rate=0.1, random_state=42)
}

# Dictionary to store results
results = []

# Train and evaluate each model
for name, model in models.items():
    model.fit(X_train, y_train)  # Train the model
    y_pred = model.predict(X_test)  # Predict on test data

    # Calculate metrics
    mae = mean_absolute_error(y_test, y_pred)   # Average absolute difference between actual & predicted values.
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Penalizes large errors more than MAE
    r2 = r2_score(y_test, y_pred)   # Measures how well the model explains variance in the target variable.

    # Store results
    results.append({"Model": name, "MAE": mae, "RMSE": rmse, "RÂ²": r2})

# Convert results to DataFrame
results_df = pd.DataFrame(results).sort_values(by="RMSE", ascending=True)

# Display results
print(results_df)

import plotly.express as px

# RMSE Comparison
fig_rmse = px.bar(results_df, x='RMSE', y='Model', orientation='h',
                   color='RMSE', color_continuous_scale='viridis',
                   title='Model RMSE Comparison')

fig_rmse.update_layout(xaxis_title='RMSE', yaxis_title='Model')
fig_rmse.show()

# RÂ² Comparison
fig_r2 = px.bar(results_df, x='RÂ²', y='Model', orientation='h',
                 color='RÂ²', color_continuous_scale='bluered',
                 title='Model RÂ² Score Comparison')

fig_r2.update_layout(xaxis_title='RÂ² Score', yaxis_title='Model')
fig_r2.show()

"""**Best Model Selection Criteria**

âœ… MAE (Mean Absolute Error): Random Forest (0.018126) is the lowest.

âœ… RMSE (Root Mean Squared Error): Random Forest (0.032539) is the lowest.

âœ… RÂ² (R-Squared Score): Linear Regression (1.000000) is the highest.


**Final Decision:**

Although Linear Regression has an RÂ² of 1.000000, this could indicate overfitting, meaning the model might not generalize well to unseen data. In real-world scenarios, such a perfect RÂ² score is rare and might suggest data leakage or a too-simple dataset.

On the other hand, Random Forest has:

âœ… The lowest RMSE (0.032539) â†’ indicating better predictive accuracy.

âœ… The lowest MAE (0.018126) â†’ meaning lower absolute errors.

âœ… A very high RÂ² (0.999044) â†’ almost as good as Linear Regression but likely more robust.

**Final Recommendation:**

ðŸš€ **Random Forest** is the best choice âœ… because it balances high accuracy with better error metrics, making it the most reliable model for real-world predictions.
"""

# Energy Consumption by Time

import plotly.express as px

df['Date'] = df['Datetime'].dt.date
df['Time'] = df['Datetime'].dt.time
fig = px.line(df.groupby('Time')['Global_active_power'].mean().reset_index(), x='Time', y='Global_active_power', title='Average Energy Consumption by Time')
fig

# Yearly Average Energy Consumption

import plotly.express as px
import plotly.graph_objects as go

# Group data by year and calculate the mean of sub-meters for each year
yearly_consumption = df[df['Datetime'].dt.year != 2006].groupby(df['Datetime'].dt.year)[['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']].mean()

# Convert index to a column for Plotly
yearly_consumption = yearly_consumption.reset_index()
yearly_consumption.rename(columns={'Datetime': 'Year'}, inplace=True)

# Create an interactive bar plot
fig = go.Figure()

# Add bars for each sub-metering
for sub_meter in ['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']:
    fig.add_trace(go.Bar(
        x=yearly_consumption['Year'],
        y=yearly_consumption[sub_meter],
        name=sub_meter
    ))

# Update layout
fig.update_layout(
    title="Yearly Average Energy Consumption per Sub-meter",
    xaxis_title="Year",
    yaxis_title="Average Energy Consumption",
    barmode='group',  # Grouped bar chart
    xaxis=dict(tickmode='array', tickvals=yearly_consumption['Year']),
    template="plotly_dark"  # Optional: Dark theme
)

# Show plot
fig.show()

# Feature Engineering
df['Hour'] = df['Datetime'].dt.hour
df['Day'] = df['Datetime'].dt.day
df['Month'] = df['Datetime'].dt.month
df['Weekday'] = df['Datetime'].dt.weekday

# Energy Consumption per Sub-meter

day_mapping = {
    0: 'Monday',
    1: 'Tuesday',
    2: 'Wednesday',
    3: 'Thursday',
    4: 'Friday',
    5: 'Saturday',
    6: 'Sunday'
}

# Convert numerical 'Weekday' column to day names
df['Day_Name'] = df['Weekday'].map(day_mapping)

# Calculate average energy consumption per day
day_consumption = df.groupby('Day_Name')[['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']].mean()

# Sort the days correctly
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
day_consumption = day_consumption.reindex(day_order)

# Plot
fig, ax = plt.subplots(figsize=(12, 6))
day_consumption.plot(kind='bar', ax=ax)
ax.set_xlabel('Days of the Week')
ax.set_ylabel('Average Energy Consumption')
ax.set_title('Average Energy Consumption per Sub-meter by Day')
ax.set_xticklabels(day_order, rotation=45, ha='right')
ax.legend(title='Sub-metering')

!pip install streamlit
!pip install pyngrok
!pip install ngrok
!pip install requests pandas streamlit
!pip list

# Code for Streamlit

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import streamlit as st
from google.colab import drive
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
import tensorflow as tf
from xgboost import XGBRegressor
import shap
import statsmodels.api as sm



# Load Dataset with Optimizations
file_path = "/content/drive/MyDrive/Household Energy Usage Forecast/household_power_consumption.txt"
df = pd.read_csv(file_path, sep=';', low_memory=False, na_values=['?'])


# Convert Date and Time into a single Datetime column
df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', dayfirst=True)
df.drop(columns=['Date', 'Time'], inplace=True)


# Fill Missing Values with Median
df.fillna(df.median(), inplace=True)


# Convert to appropriate types
df = df.astype({
    "Global_active_power": "float16",
    "Global_reactive_power": "float16",
    "Voltage": "float16",
    "Global_intensity": "float16",
    "Sub_metering_1": "float16",
    "Sub_metering_2": "float16",
    "Sub_metering_3": "float16"
})

# Feature Engineering
df['Hour'] = df['Datetime'].dt.hour
df['Day'] = df['Datetime'].dt.day
df['Month'] = df['Datetime'].dt.month
df['Weekday'] = df['Datetime'].dt.weekday

# Sample dataset to speed up training
df = df.sample(frac=0.2, random_state=42)  # Use 20% of the data for faster execution

# Define Features and Target
X = df[['Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']]
y = df['Global_active_power']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardization
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize Models
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(n_estimators=50, n_jobs=-1, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, random_state=42),
    "Neural Network": MLPRegressor(hidden_layer_sizes=(30,30), max_iter=300, early_stopping=True, random_state=42),
    "XGBoost": XGBRegressor(n_estimators=50, learning_rate=0.1, random_state=42)
}

# Streamlit Multi-Page App
st.set_page_config(page_title="Household Energy Usage Forecast", page_icon="âš¡", layout="wide")

def set_sidebar_color(bg_color="#00AEC1", text_color="#FFFFFF", selectbox_text_color="#000000"):
    st.markdown(
        f"""
        <style>
        /* Sidebar background and general text styling */
        [data-testid="stSidebar"] {{
            background-color: {bg_color} !important;
        }}

        /* General sidebar text - white and bold */
        [data-testid="stSidebar"] * {{
            color: {text_color} !important;
            font-weight: normal !important;
        }}

        /* Selectbox label - white and bold */
        [data-testid="stSidebar"] .stSelectbox label {{
            color: {text_color} !important;
            font-weight: bold !important;
        }}

        /* Selectbox dropdown and selected text - black */
        [data-testid="stSidebar"] .stSelectbox div[data-baseweb="select"] * {{
            color: {selectbox_text_color} !important;
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

# Sidebar Navigation
set_sidebar_color(bg_color="#F28AB8", text_color="#000000", selectbox_text_color="#000000")
st.sidebar.markdown(f'<iframe src="https://lottie.host/embed/40df56da-9750-49d8-8dcb-91aa890873d0/2p5TSOJHIe.lottie" width="100" height="100" style="border:none;"></iframe>', unsafe_allow_html=True)  # Use st.markdown to embed the Lottie animation as an iframe
st.sidebar.title("âš¡Household Energy")
st.sidebar.subheader("Select an Analysis")


# Sidebar Navigation
page = st.sidebar.radio("", ["Welcome", "Metrics & Visualization", "User Input for Predictions"])

if page == "Welcome":
    st.title("âš¡Welcome to the Household Energy Usage Forecast Dashboardâš¡")
    st.write("Navigate through the pages using the sidebar to explore metrics, visualizations, and predictions.")
    st.markdown(
          """
          <div style="position: fixed; bottom: 0; width: 100%; text-align: center;">
              <iframe src="https://lottie.host/embed/bc312be8-329f-4a48-a3f1-61472ac2677d/c22cCGYVZ3.lottie"
                  width="850" height="850" style="border:none;"></iframe>
          </div>
          """,
          unsafe_allow_html=True
      )



elif page == "Metrics & Visualization":
    st.title("Model Performance Metrics & Visualizations")

        # Radio buttons for different analysis options
    option = st.sidebar.radio("Visualization",
                              ["Model Performance", "Energy Consumption by Time","Energy Consumption Analysis by Month", "Energy Consumption per Sub-meter", "Yearly Average Energy Consumption", "Seasonal Energy Consumption Trends"])

    # Select Model for Prediction
    selected_model_name = st.sidebar.selectbox("Select Model", list(models.keys()))
    selected_model = models[selected_model_name]

    # Train and Evaluate Selected Model
    selected_model.fit(X_train, y_train)
    y_pred = selected_model.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    if option == "Model Performance":
        # Display Metrics
        st.write(f"### Model Performance: {selected_model_name}")
        st.write(f"**Root Mean Squared Error (RMSE):** {rmse:.4f}")  # Penalizes large errors more than MAE
        st.write(f"**Mean Absolute Error (MAE):** {mae:.4f}")        # Average absolute difference between actual & predicted values.
        st.write(f"**R-Squared (RÂ²):** {r2:.4f}")                    # Measures how well the model explains variance in the target variable.

        # Visualization using Plotly
        st.write("### Model Performance Visualization")
        fig = px.bar(x=["RMSE", "MAE", "R-Squared"], y=[rmse, mae, r2], title="Model Performance Metrics", labels={'x': 'Metric', 'y': 'Value'})
        st.plotly_chart(fig)

    elif option == "Energy Consumption by Time":
          st.write("### Energy Consumption by Time")
          # Assuming 'df' is your DataFrame and it has a 'Datetime' column
          df['Date'] = df['Datetime'].dt.date
          df['Time'] = df['Datetime'].dt.time
          fig = px.line(df.groupby('Time')['Global_active_power'].mean().reset_index(), x='Time', y='Global_active_power', title='Average Energy Consumption by Time')
          st.plotly_chart(fig)

    elif option == "Energy Consumption per Sub-meter":

          # Average Energy Consumption per Sub-meter by Day
          st.write("### Average Energy Consumption per Sub-meter by Day")
              # Mapping weekdays
          day_mapping = {
              0: 'Monday',
              1: 'Tuesday',
              2: 'Wednesday',
              3: 'Thursday',
              4: 'Friday',
              5: 'Saturday',
              6: 'Sunday'
          }

          # Convert numerical 'Weekday' column to day names
          df['Day_Name'] = df['Weekday'].map(day_mapping)

          # Calculate average energy consumption per day
          day_consumption = df.groupby('Day_Name')[['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']].mean()

          # Sort the days correctly
          day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
          day_consumption = day_consumption.reindex(day_order)

          # Plot
          fig, ax = plt.subplots(figsize=(12, 6))
          day_consumption.plot(kind='bar', ax=ax)
          ax.set_xlabel('Days of the Week')
          ax.set_ylabel('Average Energy Consumption')
          ax.set_title('Average Energy Consumption per Sub-meter by Day')
          ax.set_xticklabels(day_order, rotation=45, ha='right')
          ax.legend(title='Sub-metering')

          # Display plot in Streamlit
          st.pyplot(fig)

    elif option == "Yearly Average Energy Consumption":
          # Yearly Average Energy Consumption per Sub-meter
          st.write("### Yearly Average Energy Consumption per Sub-meter")
          # Ensure 'Datetime' is a datetime type
          df['Datetime'] = pd.to_datetime(df['Datetime'])
          # Group data by year and calculate the mean of sub-meters for each year
          yearly_consumption = df[df['Datetime'].dt.year != 2006].groupby(df['Datetime'].dt.year)[['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']].mean()
          # Plot
          fig, ax = plt.subplots(figsize=(12, 6))
          yearly_consumption.plot(kind='bar', ax=ax)
          ax.set_xlabel('Year')
          ax.set_ylabel('Average Energy Consumption')
          ax.set_title('Yearly Average Energy Consumption per Sub-meter')
          ax.set_xticklabels(yearly_consumption.index, rotation=45, ha='right')
          ax.legend(title='Sub-metering')
          # Display plot in Streamlit
          st.pyplot(fig)

    elif option == "Seasonal Energy Consumption Trends":

          st.write("### Seasonal Energy Consumption Trends")
          df['Month_Year'] = df['Datetime'].dt.to_period('M')
          monthly_avg = df.groupby('Month_Year')['Global_active_power'].mean()
          fig = px.line(x=monthly_avg.index.astype(str), y=monthly_avg.values, title='Monthly Energy Consumption Trends')
          st.plotly_chart(fig)

    elif option == "Energy Consumption Analysis by Month":

          # Load dataset (assuming 'df' is already available)
          df['Datetime'] = pd.to_datetime(df['Datetime'])

          # Month mapping
          month_mapping = {
              1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',
              7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'
          }

          # Streamlit UI
          st.title("Energy Consumption Analysis by Month")

          # Month selection
          selected_month = st.selectbox("Select a Month", list(month_mapping.values()))

          # Convert selected month back to number
          selected_month_number = list(month_mapping.keys())[list(month_mapping.values()).index(selected_month)]

          # Filter data for selected month
          filtered_df = df[df['Datetime'].dt.month == selected_month_number]

          # Group by year and calculate mean for each sub-meter
          monthly_comparison = filtered_df.groupby(filtered_df['Datetime'].dt.year)[['Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']].mean()

          # Plot
          fig, ax = plt.subplots(figsize=(12, 6))
          monthly_comparison.plot(kind='bar', ax=ax)
          ax.set_xlabel('Year')
          ax.set_ylabel('Average Energy Consumption')
          ax.set_title(f'Energy Consumption in {selected_month} Across Years')
          ax.set_xticklabels(monthly_comparison.index, rotation=45, ha='right')
          ax.legend(title='Sub-metering')

          # Show the plot in Streamlit
          st.pyplot(fig)


    # Additional Analysis: Feature Importance (Random Forest)
    if selected_model_name == "Random Forest":
        feature_importances = selected_model.feature_importances_
        importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)
        fig = px.bar(importance_df, x='Feature', y='Importance', title='Feature Importance')
        st.plotly_chart(fig)

elif page == "User Input for Predictions":
    st.title("Predict Future Energy Consumption")

    # Select Model for Prediction
    selected_model_name = st.sidebar.selectbox("Select Model", list(models.keys()))
    selected_model = models[selected_model_name]


    # Train and Evaluate Selected Model
    selected_model.fit(X_train, y_train)
    y_pred = selected_model.predict(X_test)

    input_data = pd.DataFrame([[
        st.slider("Hour", 0, 23, 12),
        st.slider("Day", 1, 31, 15),
        st.slider("Month", 1, 12, 6),
        st.slider("Weekday", 0, 6, 2),
        st.selectbox("Reactive Power", [0.1, 0.2, 0.3, 0.4]),
        st.selectbox("Voltage", [220.0, 225.0, 230.0, 235.0]),
        st.selectbox("Intensity", [4.0, 5.0, 6.0]),
        st.selectbox("Sub-Meter 1", [0.0, 1.0, 2.0]),
        st.selectbox("Sub-Meter 2", [0.0, 1.0, 2.0]),
        st.selectbox("Sub-Meter 3", [0.0, 1.0, 2.0])
    ]], columns=X.columns)

    if st.button("Predict"):
        input_data = scaler.transform(input_data)
        prediction = selected_model.predict(input_data)[0]
        st.write(f"### Predicted Energy Consumption: {prediction:.2f} kW")


# Footer
st.sidebar.markdown("---")
st.sidebar.info(
    "âš¡ **Household Energy Usage Forecast Dashboard**  \n"
    "ðŸ‘©â€ðŸ’» Developed by **Mubina**  \n"
    "ðŸ”— [GitHub Repository](https://github.com/SMMubina/Household-Energy-Usage-Forecast)")

# Set your ngrok auth token
from pyngrok import ngrok
ngrok.set_auth_token("2qYh3WXfLyTfZiBiskvg0VXMXds_4bHusVSb8aaK2WHaf6HKz")


# Start ngrok tunnel
public_url = ngrok.connect(8501)
print(f"Streamlit app is live at: {public_url}")

# Run the Streamlit app
!streamlit run work.py &>/dev/null&